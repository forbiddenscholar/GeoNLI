{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee83a766",
   "metadata": {},
   "source": [
    "# GeoNLI Backend (Django)\n",
    "\n",
    "This is the backend server for the GeoNLI application. It is built with Django and provides APIs for image processing, chat interactions, and multi-modal inference (Captioning, VQA, Grounding).\n",
    "\n",
    "## Key Features\n",
    "\n",
    "*   **Hybrid Inference Pipeline:** Automatically routes image processing based on image type:\n",
    "    *   **RGB Images:** Processed locally/via cloud using the **Moondream** library.\n",
    "    *   **SAR (Synthetic Aperture Radar) Images:** Routed to a specialized external SAR model API.\n",
    "*   **Automatic Classification:** Uses an external CNN classifier to determine if an uploaded image is RGB or SAR.\n",
    "*   **Session Management:** Persists chat sessions, message history, and image metadata (including classification type).\n",
    "*   **RESTful API:** Endpoints for image upload, chat interactions, and history management.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "*   Python 3.10+\n",
    "*   Pip (Python package manager)\n",
    "*   External services (optional but recommended for full functionality):\n",
    "    *   CNN Image Classifier Service\n",
    "    *   Hosted SAR Model Service\n",
    "\n",
    "## Installation\n",
    "\n",
    "1.  **Navigate to the backend directory:**\n",
    "    ```bash\n",
    "    cd website-updated\n",
    "    ```\n",
    "\n",
    "2.  **Create a virtual environment (optional but recommended):**\n",
    "    ```bash\n",
    "    python -m venv venv\n",
    "    source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "    ```\n",
    "\n",
    "3.  **Install dependencies:**\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Create a `.env` file in the `website-updated` directory to configure your API keys and external service URLs.\n",
    "\n",
    "```ini\n",
    "# .env\n",
    "\n",
    "# Django Secret Key (Generate a secure random string for production)\n",
    "SECRET_KEY=your_django_secret_key\n",
    "\n",
    "# Debug Mode (Set to False in production)\n",
    "DEBUG=True\n",
    "\n",
    "# Moondream API Key (Required for RGB image processing)\n",
    "MOONDREAM_API_KEY=your_moondream_api_key\n",
    "\n",
    "# --- External Services Configuration ---\n",
    "\n",
    "# URL for the CNN Classifier that distinguishes RGB vs SAR\n",
    "CNN_CLASSIFIER_URL=http://localhost:5000/classify\n",
    "\n",
    "# URL for the hosted SAR Model inference API\n",
    "SAR_MODEL_URL=http://localhost:5001/v1/inference\n",
    "\n",
    "# API Key for the SAR Model (if required)\n",
    "SAR_API_KEY=your_sar_api_key\n",
    "```\n",
    "\n",
    "## Database Setup\n",
    "\n",
    "Run the initial migrations to set up the SQLite database:\n",
    "\n",
    "```bash\n",
    "python manage.py migrate\n",
    "```\n",
    "\n",
    "## Running the Server\n",
    "\n",
    "Start the Django development server:\n",
    "\n",
    "```bash\n",
    "python manage.py runserver\n",
    "```\n",
    "\n",
    "The server will start at `http://localhost:8000`.\n",
    "\n",
    "## API Endpoints\n",
    "\n",
    "### 1. Upload Image\n",
    "*   **URL:** `/geoNLI/upload`\n",
    "*   **Method:** `POST`\n",
    "*   **Body:** `form-data` with key `image` (file).\n",
    "*   **Response:** Returns `image_url`, `session_id`, and detected `image_type` ('RGB' or 'SAR').\n",
    "\n",
    "### 2. Chat / Inference\n",
    "*   **URL:** `/geoNLI/chat`\n",
    "*   **Method:** `POST`\n",
    "*   **Body:**\n",
    "    ```json\n",
    "    {\n",
    "      \"image_url\": \"http://...\",\n",
    "      \"session_id\": 1,\n",
    "      \"message\": \"Describe this image\",\n",
    "      \"mode\": \"captioning\"  // Options: \"captioning\", \"vqa\", \"grounding\"\n",
    "    }\n",
    "    ```\n",
    "*   **Response:** Returns the model's text response or grounding objects.\n",
    "\n",
    "### 3. Chat History\n",
    "*   **URL:** `/geoNLI/history`\n",
    "*   **Method:** `GET`\n",
    "*   **Response:** List of recent chat sessions.\n",
    "\n",
    "### 4. Session Messages\n",
    "*   **URL:** `/geoNLI/history/<session_id>`\n",
    "*   **Method:** `GET`\n",
    "*   **Response:** Full conversation history for a specific session.\n",
    "\n",
    "## Testing\n",
    "\n",
    "To run the API integration tests:\n",
    "\n",
    "```bash\n",
    "# Ensure the server is running in another terminal first!\n",
    "python test_api.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b771",
   "metadata": {},
   "source": [
    "# User Guide\n",
    "\n",
    "## 1. Introduction\n",
    "The application provides a complete pipeline for natural-language interpretation of satellite imagery, supporting captioning, grounding, and visual question answering.  \n",
    "This guide explains how to set up the deployment package and operate the interface to run inference.  \n",
    "The setup is lightweight and requires only minimal environment preparation using the files provided.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. System Requirements\n",
    "No special system requirements are needed beyond a working Python installation (Python 3.x).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Installation\n",
    "\n",
    "### 3.1 Unzip the Deployment Package\n",
    "Extract the provided ZIP file.  \n",
    "It contains the full project folder along with all required checkpoints.\n",
    "\n",
    "### 3.2 Create a Virtual Environment\n",
    "Run the following commands:\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate      # Linux/Mac\n",
    "venv\\Scripts\\activate         # Windows\n",
    "```\n",
    "\n",
    "### 3.3 Install Dependencies    \n",
    "\n",
    "Install all required Python packages using the provided `requirements.txt` file:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 3.4 Download SAM 2.1 Source Code\n",
    "\n",
    "Download the official SAM 2.1 source repository:\n",
    "```bash\n",
    "wget https://github.com/facebookresearch/sam2/archive/refs/heads/main.zip -O sam2_source.zip\n",
    "```\n",
    "\n",
    "### 3.5 Unzip SAM 2.1\n",
    "\n",
    "Extract the downloaded SAM 2.1 source archive:\n",
    "```bash\n",
    "unzip sam2_source.zip\n",
    "```\n",
    "\n",
    "### 3.6 Install SAM 2.1 in Editable Mode\n",
    "\n",
    "Navigate to the extracted directory and install SAM 2.1:\n",
    "```bash\n",
    "cd sam2-main\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "### 3.7 Return to the Main Project Directory\n",
    "```bash\n",
    "cd ..\n",
    "```\n",
    "\n",
    "## 4. Running the Application\n",
    "\n",
    "### 4.1 Start the Flask Server\n",
    "\n",
    "Launch the application server in debug mode:\n",
    "```bash\n",
    "flask --app VLMHosting run --debug\n",
    "```\n",
    "## 5. Operating the Website for Inference\n",
    "\n",
    "### 5.1 Uploading an Image\n",
    "\n",
    "1. On the front page of the website, you will see an **Upload Image** option\n",
    "2. Click on the upload button and select a satellite image from your local system\n",
    "3. Supported formats include common image types (JPEG, PNG, etc.)\n",
    "4. Once uploaded, the interface will split into two sections:\n",
    "   - **Left half**: Interactive chatbot interface\n",
    "   - **Right half**: Your uploaded satellite image\n",
    "\n",
    "### 5.2 Interacting with the Chatbot\n",
    "\n",
    "The chatbot provides three primary modes of interaction for analyzing your satellite imagery:\n",
    "\n",
    "#### 5.2.1 Captioning\n",
    "- Generate natural language descriptions of the satellite image\n",
    "- The model will provide a comprehensive caption describing the contents, features, and characteristics visible in the image\n",
    "- Simply type your request (e.g., \"Describe this image\" or \"Generate a caption\")\n",
    "\n",
    "#### 5.2.2 Visual Question Answering (VQA)\n",
    "Ask questions about the image in three different categories:\n",
    "\n",
    "- **Binary VQA**: Ask yes/no questions about the image\n",
    "  - Example: \"Is there a river in this image?\"\n",
    "  - Example: \"Are there buildings present?\"\n",
    "\n",
    "- **Semantic VQA**: Ask descriptive questions requiring detailed answers\n",
    "  - Example: \"What type of terrain is shown?\"\n",
    "  - Example: \"What structures are visible in the center?\"\n",
    "\n",
    "- **Numeric VQA**: Ask questions that require numerical answers\n",
    "  - Example: \"How many buildings are visible?\"\n",
    "  - Example: \"What is the approximate area coverage?\"\n",
    "\n",
    "#### 5.2.3 Grounding\n",
    "- Identify and locate specific objects or features within the image\n",
    "- The system will highlight or mark the requested features on the displayed image\n",
    "- Example: \"Locate all buildings in the image\"\n",
    "- Example: \"Show me where the roads are\"\n",
    "\n",
    "### 5.3 Viewing Chat History\n",
    "\n",
    "- The chatbot interface includes a **History** option\n",
    "- Click on the history button to view your previous interactions and queries\n",
    "- This allows you to:\n",
    "  - Review past questions and answers\n",
    "  - Revisit previous image analyses\n",
    "  - Track your inference sessions\n",
    "\n",
    "### 5.4 Tips for Best Results\n",
    "\n",
    "- **Be specific**: Clearly state what you want to know about the image\n",
    "- **Choose the right mode**: Select the appropriate interaction type (captioning, VQA, or grounding) based on your needs\n",
    "- **Experiment**: Try different question types to explore the full capabilities of the system\n",
    "- **Use history**: Reference your previous queries to build upon earlier analyses\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
